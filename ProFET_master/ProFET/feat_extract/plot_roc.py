"""
=============================================================
Receiver Operating Characteristic (ROC) with cross validation
=============================================================


ROC curves typically feature true positive rate on the Y axis, and false
positive rate on the X axis. This means that the top left corner of the plot is
the "ideal" point - a false positive rate of zero, and a true positive rate of
one. This is not very realistic, but it does mean that a larger area under the
curve (AUC) is usually better.

This example shows the ROC response of different datasets, created from K-fold
cross-validation. Taking all of these curves, it is possible to calculate the
mean area under curve, and see the variance of the curve when the
training set is split into different subsets. This roughly shows how the
classifier output is affected by changes in the training data, and how
different the splits generated by K-fold cross-validation are from one another.

.. note::

    See also :func:`sklearn.metrics.auc_score`,
             :func:`sklearn.cross_validation.cross_val_score`,
             :ref:`example_plot_roc.py`,

"""
# print(__doc__)

import numpy as np
from scipy import interp
import matplotlib.pyplot as plt

from sklearn import svm, datasets
from sklearn.metrics import roc_curve, auc
from sklearn.cross_validation import StratifiedKFold
from sklearn.metrics import roc_curve, auc
from sklearn import metrics
from sys import argv
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression,  RandomizedLogisticRegression
from sklearn.svm import SVC,LinearSVC
from sklearn.grid_search import GridSearchCV
from sklearn.cross_validation import StratifiedKFold,cross_val_score,StratifiedShuffleSplit

from sklearn.feature_selection import RFE, RFECV, SelectFdr,SelectFwe,SelectKBest

from sklearn.pipeline import Pipeline
from sklearn.metrics import f1_score
from PipeTasks import Get_yPred,balance_weights
from collections import Counter
from sklearn.dummy import DummyClassifier
import os, fnmatch

from sklearn.preprocessing import LabelEncoder
import numpy as np

from sklearn import svm, datasets
from sklearn.metrics import roc_curve, auc
from sklearn.cross_validation import train_test_split
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
import os, fnmatch
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from PipeTasks import Get_yPred,balance_weights
###############################################################################
# Data IO and generation

# os.chdir(r'/a/fr-05/vol/protein/danofer/ProtFeat/feat_extract/test_seq/Thermophile')
##os.chdir(r'/cs/prt3/danofer/ProtFeat/feat_extract/test_seq/NP/SP_Cleaved+NP+Neg_Big')

filePaths = ['/cs/prt3/danofer/ProtFeat/feat_extract/test_seq/NP/SP_Cleaved+NP+Neg_Big','/a/fr-05/vol/protein/danofer/ProtFeat/feat_extract/test_seq/Thermophile']
fileNames = ['Neuropeptide Precursors','Thermophiles']
lineColours = [(':','red'),('-','blue'),('--','green')]

plt.figure(dpi=270)

n=-1
for filepath in filePaths:
    n +=1
    fileName=fileNames[n]

    os.chdir(filepath)
    df = pd.read_csv('trainingSetFeatures.csv')
    ##    df.drop('proteinname',axis=1, inplace=True)
    feature_cols = [col for col in df.columns if col not in ['classname','Id','proteinname']]
    X=df[feature_cols].values
    y=df.classname.values

    Fwe = SelectFwe(alpha=0.01).fit(X,y)
    X=Fwe.transform(X)

    le = LabelEncoder()
    y = le.fit_transform(y)

    #Orig
    # X, y = X[y != 2], y[y != 2]  #Orig
    n_samples, n_features = X.shape #Orig

    n_classes=len(set(y))
    target_names=list(le.classes_)
    print ("n_classes",n_classes,"target_names",target_names)

    ###############################################################################
    # Classification and ROC analysis

    # Run classifier with cross-validation and plot ROC curves
    cv = StratifiedKFold(y, n_folds=13,shuffle=True) #Maybe try shuffle=True ?


    'Best hyper param  classifiers For Thermophiles:'
    # svm=SVC(C=50, cache_size=1500, class_weight='auto', gamma=0.0, kernel='rbf', probability=True)
    # rf = RandomForestClassifier(n_jobs=-1,min_samples_split= 3, max_features= 0.4, min_samples_leaf= 2, n_estimators= 200, max_depth= 8)

    'Best hyper param  classifiers For NP:'
    svm =SVC(C=50, cache_size=1800, class_weight='auto',gamma=0.0, kernel='rbf', max_iter=-1, probability=True )
    rf = RandomForestClassifier(max_depth= None, min_samples_split= 3, min_samples_leaf= 1, n_estimators= 250,  n_jobs= -1, max_features= "auto")

    classifier = svm

    mean_tpr = 0.0
    mean_fpr = np.linspace(0, 1, 100)
    all_tpr = []

    for i, (train, test) in enumerate(cv):
        probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])
        # Compute ROC curve and area the curve
        fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])
        mean_tpr += interp(mean_fpr, fpr, tpr)
        mean_tpr[0] = 0.0
        roc_auc = auc(fpr, tpr)
        # plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))
    mean_tpr /= len(cv)
    mean_tpr[-1] = 1.0
    mean_auc = auc(mean_fpr, mean_tpr)

    # plt.plot(mean_fpr, mean_tpr, 'k--',
    #          label='%s: Mean ROC (area = %0.2f)' % (fileName,mean_auc), lw=2)
    plt.plot(mean_fpr, mean_tpr, lineColours[n][0],
             label='%s \n Mean ROC (area = %0.2f)' % (fileName,mean_auc),lw=2,
             color=lineColours[n][1])
    # sns.plot(mean_fpr, mean_tpr)

plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')

# mean_tpr /= len(cv)
# mean_tpr[-1] = 1.0
# mean_auc = auc(mean_fpr, mean_tpr)
# plt.plot(mean_fpr, mean_tpr, 'k--',
#          label='%s: Mean ROC (area = %0.2f)' % (fileName,mean_auc), lw=2)
# plt.plot(mean_fpr, [i/2 for i in mean_tpr], 'k--',
#          label='%s: YYY ROC (area = %0.2f)' % (fileName,mean_auc), lw=2, color='red')

plt.xlim([-0.01, 1.02])
plt.ylim([-0.01, 1.02])
plt.grid('off')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC (Receiver operating characteristic) Curves')
plt.legend(loc="lower right")
plt.tight_layout()
plt.ion()
plt.show()
